{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from vllm import LLM, SamplingParams\n",
    "from outlines.serve.vllm import JSONLogitsProcessor\n",
    "from pydantic import BaseModel, conlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 06-08 20:52:01 config.py:211] gptq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "INFO 06-08 20:52:01 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='/home/liyinghao/share/yhli/models/Llama-2-70B-GPTQ', tokenizer='/home/liyinghao/share/yhli/models/Llama-2-70B-GPTQ', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=gptq, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, seed=0)\n",
      "INFO 06-08 20:52:11 selector.py:16] Using FlashAttention backend.\n",
      "INFO 06-08 20:56:55 model_runner.py:104] Loading model weights took 32.8865 GB\n",
      "INFO 06-08 20:57:00 gpu_executor.py:94] # GPU blocks: 536, # CPU blocks: 819\n"
     ]
    }
   ],
   "source": [
    "model_path = '/home/liyinghao/share/yhli/models/Llama-2-70B-GPTQ'\n",
    "llm = LLM(\n",
    "    model=model_path,\n",
    "    tokenizer=model_path,\n",
    "    gpu_memory_utilization=0.95,\n",
    "    max_num_seqs=1,\n",
    "    enforce_eager=True,\n",
    "    tensor_parallel_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(\n",
    "    temperature=0, \n",
    "    max_tokens=100,\n",
    "    include_stop_str_in_output=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question:\n",
      "What are the names of some famous actors that started their careers on Broadway?\n",
      "Answer: \n",
      "\n",
      "Question:\n",
      "What are the names of some famous actors that started their careers on Broadway?\n",
      "Answer: \n",
      "\n",
      "Question:\n",
      "What are the names of some famous actors that started their careers on Broadway?\n",
      "Answer: \n",
      "\n",
      "Question:\n",
      "What are the names of some famous actors that started their careers on Broadway?\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "query = '''Below is a list of conversations between a human and an AI assistant (you). \n",
    "Users place their queries under \"Query:\", and your responses are under \"Answer:\".\n",
    "You are a helpful, respectful, and honest assistant.\n",
    "You should always answer as helpfully as possible while ensuring safety.\n",
    "Your answers should be well-structured and provide detailed information. They should also have an engaging tone.\n",
    "Your responses must not contain any fake, harmful, unethical, racist, sexist, toxic, dangerous, or illegal content, even if it may be helpful.\n",
    "Your response must be socially responsible, and thus you can reject to answer some controversial topics.\n",
    "\n",
    "Question:\n",
    "What are the names of some famous actors that started their careers on Broadway?\n",
    "Answer: '''\n",
    "print(llm.generate(query, sampling_params, use_tqdm=False)[0].outputs[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
